# analyze_glpi_patterns.py - An√°lise de Padr√µes de Chamados GLPI
import os
import requests
import json
import re
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from dotenv import load_dotenv

load_dotenv()

# Configura√ß√µes do GLPI
GLPI_URL = os.getenv("GLPI_URL")
GLPI_APP_TOKEN = os.getenv("GLPI_APP_TOKEN")
GLPI_USER_TOKEN = os.getenv("GLPI_USER_TOKEN")

class GLPIAnalyzer:
    def __init__(self):
        self.session_token = None
        self.tickets = []
        self.categories = {}
        self.analysis_results = {}
        
    def authenticate(self):
        """Autentica no GLPI"""
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"user_token {GLPI_USER_TOKEN}",
                "App-Token": GLPI_APP_TOKEN
            }
            
            response = requests.get(f"{GLPI_URL}/initSession", headers=headers)
            response.raise_for_status()
            
            result = response.json()
            self.session_token = result.get("session_token")
            print(f"‚úÖ Autenticado no GLPI com sucesso")
            return True
            
        except Exception as e:
            print(f"‚ùå Erro na autentica√ß√£o: {str(e)}")
            return False
    
    def get_headers(self):
        """Retorna headers para requisi√ß√µes autenticadas"""
        return {
            "Content-Type": "application/json",
            "Session-Token": self.session_token,
            "App-Token": GLPI_APP_TOKEN
        }
    
    def fetch_tickets(self, limit=100):
        """Busca tickets recentes do GLPI"""
        try:
            headers = self.get_headers()
            
            # Tenta diferentes formas de buscar tickets
            attempts = [
                # Tentativa 1: Com par√¢metros completos
                {
                    'url': f"{GLPI_URL}/Ticket",
                    'params': {
                        'range': f'0-{limit-1}',
                        'sort': 'id',
                        'order': 'DESC'
                    }
                },
                # Tentativa 2: Apenas com range
                {
                    'url': f"{GLPI_URL}/Ticket",
                    'params': {
                        'range': f'0-{limit-1}'
                    }
                },
                # Tentativa 3: Sem par√¢metros
                {
                    'url': f"{GLPI_URL}/Ticket",
                    'params': {}
                }
            ]
            
            for attempt in attempts:
                try:
                    response = requests.get(attempt['url'], headers=headers, params=attempt['params'])
                    if response.status_code == 200:
                        tickets_data = response.json()
                        # Se retornou uma lista, usa diretamente, sen√£o tenta extrair
                        if isinstance(tickets_data, list):
                            self.tickets = tickets_data[:limit]
                        elif isinstance(tickets_data, dict) and 'data' in tickets_data:
                            self.tickets = tickets_data['data'][:limit]
                        else:
                            self.tickets = [tickets_data] if tickets_data else []
                        
                        print(f"‚úÖ Coletados {len(self.tickets)} tickets")
                        return True
                except Exception as e:
                    print(f"‚ö†Ô∏è  Tentativa falhou: {str(e)}")
                    continue
            
            print(f"‚ùå N√£o foi poss√≠vel buscar tickets")
            return False
                
        except Exception as e:
            print(f"‚ùå Erro ao buscar tickets: {str(e)}")
            return False
    
    def fetch_categories(self):
        """Busca categorias do GLPI"""
        try:
            headers = self.get_headers()
            
            # Tenta diferentes endpoints para categorias
            endpoints = [
                f"{GLPI_URL}/ITILCategory",
                f"{GLPI_URL}/itilcategory", 
                f"{GLPI_URL}/ItilCategory"
            ]
            
            for endpoint in endpoints:
                try:
                    response = requests.get(endpoint, headers=headers)
                    if response.status_code == 200:
                        categories_data = response.json()
                        for cat in categories_data:
                            self.categories[cat.get('id')] = cat.get('name', 'Sem categoria')
                        print(f"‚úÖ Coletadas {len(self.categories)} categorias")
                        return True
                except:
                    continue
            
            print(f"‚ö†Ô∏è  N√£o foi poss√≠vel buscar categorias, continuando sem elas")
            return True  # Continua a an√°lise mesmo sem categorias
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao buscar categorias: {str(e)}, continuando sem elas")
            return True  # Continua a an√°lise mesmo sem categorias
    
    def analyze_descriptions(self):
        """Analisa padr√µes nas descri√ß√µes dos chamados"""
        print("\nüîç AN√ÅLISE DE DESCRI√á√ïES")
        print("=" * 50)
        
        descriptions = []
        short_descriptions = []
        vague_descriptions = []
        missing_info = []
        
        # Palavras que indicam descri√ß√µes vagas
        vague_indicators = [
            'n√£o funciona', 'com problema', 'n√£o est√° funcionando', 'quebrado',
            'parou', 'travou', 'lento', 'erro', 'problema', 'ajuda', 'urgente'
        ]
        
        # Informa√ß√µes importantes que podem estar faltando
        important_info = [
            'local', 'sala', 'andar', 'pr√©dio', 'setor',
            'telefone', 'contato', 'ramal',
            'erro', 'mensagem', 'c√≥digo',
            'quando', 'hor√°rio', 'desde quando'
        ]
        
        for ticket in self.tickets:
            content = ticket.get('content', '').lower()
            name = ticket.get('name', '').lower()
            full_text = f"{name} {content}"
            
            descriptions.append(len(content))
            
            # Verifica descri√ß√µes muito curtas (menos de 20 caracteres)
            if len(content) < 20:
                short_descriptions.append({
                    'id': ticket.get('id'),
                    'name': ticket.get('name'),
                    'content': ticket.get('content'),
                    'length': len(content)
                })
            
            # Verifica descri√ß√µes vagas
            vague_count = sum(1 for indicator in vague_indicators if indicator in full_text)
            if vague_count > 0 and len(content) < 50:
                vague_descriptions.append({
                    'id': ticket.get('id'),
                    'name': ticket.get('name'),
                    'content': ticket.get('content'),
                    'vague_indicators': vague_count
                })
            
            # Verifica informa√ß√µes faltantes
            missing_count = sum(1 for info in important_info if info not in full_text)
            if missing_count > 6:  # Se faltam mais de 6 tipos de informa√ß√£o
                missing_info.append({
                    'id': ticket.get('id'),
                    'name': ticket.get('name'),
                    'content': ticket.get('content'),
                    'missing_score': missing_count
                })
        
        # Estat√≠sticas
        avg_length = sum(descriptions) / len(descriptions) if descriptions else 0
        
        self.analysis_results['descriptions'] = {
            'total_tickets': len(self.tickets),
            'average_length': round(avg_length, 2),
            'short_descriptions': len(short_descriptions),
            'vague_descriptions': len(vague_descriptions),
            'missing_info': len(missing_info),
            'examples': {
                'short': short_descriptions[:5],
                'vague': vague_descriptions[:5],
                'missing': missing_info[:5]
            }
        }
        
        print(f"üìä Total de tickets analisados: {len(self.tickets)}")
        print(f"üìè Comprimento m√©dio das descri√ß√µes: {avg_length:.1f} caracteres")
        print(f"‚ö†Ô∏è  Descri√ß√µes muito curtas (<20 chars): {len(short_descriptions)} ({len(short_descriptions)/len(self.tickets)*100:.1f}%)")
        print(f"ü§î Descri√ß√µes vagas: {len(vague_descriptions)} ({len(vague_descriptions)/len(self.tickets)*100:.1f}%)")
        print(f"‚ùì Faltam informa√ß√µes importantes: {len(missing_info)} ({len(missing_info)/len(self.tickets)*100:.1f}%)")
    
    def analyze_categories(self):
        """Analisa padr√µes de categoriza√ß√£o"""
        print("\nüìÇ AN√ÅLISE DE CATEGORIZA√á√ÉO")
        print("=" * 50)
        
        category_usage = Counter()
        uncategorized = 0
        
        for ticket in self.tickets:
            cat_id = ticket.get('itilcategories_id')
            if cat_id and cat_id != '0':
                category_name = self.categories.get(int(cat_id), f'ID:{cat_id}')
                category_usage[category_name] += 1
            else:
                uncategorized += 1
        
        self.analysis_results['categories'] = {
            'total_categories': len(category_usage),
            'uncategorized': uncategorized,
            'most_used': category_usage.most_common(10),
            'distribution': dict(category_usage)
        }
        
        print(f"üìä Categorias utilizadas: {len(category_usage)}")
        print(f"‚ùå Chamados sem categoria: {uncategorized} ({uncategorized/len(self.tickets)*100:.1f}%)")
        print(f"\nüèÜ Top 5 categorias mais usadas:")
        for i, (category, count) in enumerate(category_usage.most_common(5), 1):
            percentage = count/len(self.tickets)*100
            print(f"   {i}. {category}: {count} tickets ({percentage:.1f}%)")
    
    def analyze_impact_urgency(self):
        """Analisa padr√µes de impacto e urg√™ncia"""
        print("\n‚ö° AN√ÅLISE DE IMPACTO E URG√äNCIA")
        print("=" * 50)
        
        impact_map = {1: 'Muito Baixo', 2: 'Baixo', 3: 'M√©dio', 4: 'Alto', 5: 'Muito Alto'}
        urgency_map = {1: 'Muito Baixa', 2: 'Baixa', 3: 'M√©dia', 4: 'Alta', 5: 'Muito Alta'}
        
        impact_usage = Counter()
        urgency_usage = Counter()
        priority_usage = Counter()
        
        for ticket in self.tickets:
            impact = ticket.get('impact', 0)
            urgency = ticket.get('urgency', 0)
            priority = ticket.get('priority', 0)
            
            impact_usage[impact_map.get(impact, f'ID:{impact}')] += 1
            urgency_usage[urgency_map.get(urgency, f'ID:{urgency}')] += 1
            priority_usage[priority] += 1
        
        self.analysis_results['impact_urgency'] = {
            'impact_distribution': dict(impact_usage),
            'urgency_distribution': dict(urgency_usage),
            'priority_distribution': dict(priority_usage)
        }
        
        print("üìä Distribui√ß√£o de Impacto:")
        for impact, count in impact_usage.most_common():
            percentage = count/len(self.tickets)*100
            print(f"   {impact}: {count} tickets ({percentage:.1f}%)")
        
        print("\nüìä Distribui√ß√£o de Urg√™ncia:")
        for urgency, count in urgency_usage.most_common():
            percentage = count/len(self.tickets)*100
            print(f"   {urgency}: {count} tickets ({percentage:.1f}%)")
    
    def generate_recommendations(self):
        """Gera recomenda√ß√µes baseadas na an√°lise"""
        print("\nüí° RECOMENDA√á√ïES PARA MELHORIA")
        print("=" * 50)
        
        recommendations = []
        
        # An√°lise de descri√ß√µes
        desc_data = self.analysis_results.get('descriptions', {})
        short_pct = (desc_data.get('short_descriptions', 0) / desc_data.get('total_tickets', 1)) * 100
        vague_pct = (desc_data.get('vague_descriptions', 0) / desc_data.get('total_tickets', 1)) * 100
        
        if short_pct > 20:
            recommendations.append({
                'priority': 'ALTA',
                'category': 'Descri√ß√µes',
                'issue': f'{short_pct:.1f}% das descri√ß√µes s√£o muito curtas',
                'solution': 'Implementar perguntas direcionadas e templates por categoria'
            })
        
        if vague_pct > 15:
            recommendations.append({
                'priority': 'ALTA',
                'category': 'Descri√ß√µes',
                'issue': f'{vague_pct:.1f}% das descri√ß√µes s√£o vagas',
                'solution': 'Adicionar perguntas espec√≠ficas sobre sintomas e contexto'
            })
        
        # An√°lise de categoriza√ß√£o
        cat_data = self.analysis_results.get('categories', {})
        uncat_pct = (cat_data.get('uncategorized', 0) / desc_data.get('total_tickets', 1)) * 100
        
        if uncat_pct > 10:
            recommendations.append({
                'priority': 'M√âDIA',
                'category': 'Categoriza√ß√£o',
                'issue': f'{uncat_pct:.1f}% dos chamados n√£o t√™m categoria',
                'solution': 'Tornar a sele√ß√£o de categoria obrigat√≥ria com op√ß√µes claras'
            })
        
        self.analysis_results['recommendations'] = recommendations
        
        for i, rec in enumerate(recommendations, 1):
            print(f"{i}. üî¥ {rec['priority']} - {rec['category']}")
            print(f"   Problema: {rec['issue']}")
            print(f"   Solu√ß√£o: {rec['solution']}\n")
    
    def save_results(self):
        """Salva resultados da an√°lise em arquivo"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"glpi_analysis_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Resultados salvos em: {filename}")
    
    def run_analysis(self):
        """Executa an√°lise completa"""
        print("üöÄ INICIANDO AN√ÅLISE DE PADR√ïES GLPI")
        print("=" * 50)
        
        if not self.authenticate():
            return False
        
        if not self.fetch_categories():
            return False
        
        if not self.fetch_tickets():
            return False
        
        self.analyze_descriptions()
        self.analyze_categories()
        self.analyze_impact_urgency()
        self.generate_recommendations()
        self.save_results()
        
        print("\n‚úÖ AN√ÅLISE CONCLU√çDA COM SUCESSO!")
        return True

if __name__ == "__main__":
    analyzer = GLPIAnalyzer()
    analyzer.run_analysis()